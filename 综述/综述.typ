#import "@preview/rubber-article:0.1.0": *
#import "@preview/mitex:0.2.4": *

#show: article.with()

#set text(font:("Times New Roman","Source Han Serif SC"), size: 12pt) 
// #import "@preview/cuti:0.2.1": show-cn-fakebold
// #show: show-cn-fakebold
#let 行间距转换(正文字体,行间距) = ((行间距)/(正文字体)-0.75)*1em
// // #show par: set block(spacing: 行间距转换(12,20))
#set par(leading: 行间距转换(12,20),justify: true,first-line-indent: 2em)
#show heading: it =>  {
    // set text(font: ("Times New Roman","Source Han Serif SC"), size: 12pt)
    it
    par()[
      #if it.level==1{
        v(-0.3em)
      }
      #if it.level==2{
        v(0.2em)
      }
      #if it.level==3{
        v(0.2em)
      }
      #text()[#h(0.0em)]
      #v(-1em)
      ]
      }
       
// #set par(justify: true,first-line-indent: 2em)
// #show: show-cn-fakebold
// #maketitle(
//   title: "能量机关仿真手册",
//   authors: (
//     "洛白",
//   ),
//   date: "2024 10 月22 日",
// )
// 
#v(-1em)
#align(center,
  [
    // #v(24pt)
  #text([机器人领域论文阅读综述], size:16pt,weight: "bold",font:"Source Han Serif SC")
//  #v(-0.2em)
//   #text([物理与光电工程学院], size:12pt,font:"Source Han Serif SC")
//   #h(1em) #text([2021251124 ], size:12pt,font:"Times New Roman")
//   #text([古翱翔], size:12pt,font:"Source Han Serif SC")
  
  ])


#v(1em)
// #bibliography("use.bib", title: [
// 参考文献#v(1em)
// ],style: "nature")

= SLAM 
#v(2em)
== A Intorduce to SLAM @grisetti2010tutorial
为了高效地完成移动机器人所承担的诸多任务，如运输、搜索与救援或自动吸尘器等，这些机器人需要具备*环境地图*。

拥有准确的地图使得系统能够在仅依赖于机载传感器而不依靠外部参考系统（例如GPS）的情况下，在复杂环境中进行操作成为可能。在过去几十年里，机器人研究领域的主要研究焦点之一就是在没有GPS信号的室内环境中获取地图的技术。*在存在位置不确定性的情况下学习构建地图通常被称为同步定位与建图（SLAM）问题*。在文献中，针对该问题的各种解决方案已经得到了广泛的讨论和研究。

这些方法可以根据其是否属于滤波或平滑来分类。滤波方法将问题视为在线状态估计，其中的状态被认为是随时间变化的；而平滑方法则是在离线状态下对系统进行处理，通过对已知数据进行优化来提高地图的准确性。

系统由当前机器人位置和地图组成。随着新测量数据的不断获取，该估计值将被增补并不断优化。诸如卡尔曼滤波器[28]、[3]、粒子滤波器[22]、[12]、[9]或信息滤波器[7]、[31]等流行技术都属于此类别。为了突显其增量特性，过滤方法通常被称为在线SLAM方法。

相反，平滑方法从所有测量数据中估计机器人的完整路径[21]、[5]、[27]。这些方法解决所谓的完整SLAM问题，并且通常依赖于最小二乘误差最小化技术。
== 三维刚体运动
本节主要讲解一个刚体在三维空间中的运动是如何描述的。我们当然知道这由一次旋转加一次
平移组成。平移确实没有太大问题，但旋转的处理是件麻烦事。我们将介绍旋转矩阵、四
元数、欧拉角的意义，以及它们是如何运算和转换的。
=== 基础
$
  mat(
    
)
$
=== 旋转矩阵

如果了解过线性代数的知识的话，相比对旋转矩阵不陌生。
=== 欧拉角
=== 四元数
= 人机交互
= 

= 环境感知
#h(-0.5em)
== RoboKeyGen：基于扩散模型的机器人姿态与关节角度估计方法
在智能机器人中，估计机器人姿态和关节角度对于多机器人协作[1]、在线手眼标定[2]以及闭环控制下的视觉伺服[3]都至关重要。大量研究已经集中在机器人姿态的估计上，例如基于标记的手眼标定方法[4]以及基于学习的实时校准方法[5][6][7]等。然而，这些方法假设关节角度已知，这在某些情况下并不总是成立。例如，在多机器人协作中，状态数据可能未共享，因此需要同时估计机器人姿态和关节角度。与已知或未知关节角度下的机器人姿态估计相比，后者由于自由度增加（例如，从Franka的6D到13D）而显得更加复杂。现有方法可以分为两类：渲染对比方法[8]和基于关键点的方法[9]。RoboPose [8]扩展了渲染对比策略[10][11]，将其从刚体姿态估计[12][13]推广到了机器人领域。

我们通过将目标分解为两个更易处理的任务来实现这一目标：即从RGB图像中检测2D关键点，并将这些2D关键点提升至3D，以估计机器人的姿态和关节角度。RoboKeyGen由此产生。

然而，该方法由于迭代渲染的原因，在单一帧模式下推断速度较慢（仅为1 FPS）。相比之下，SPDH [9] 引入了一种半透视解耦热力图表示法，将广为人知的2D热力图扩展到了3D领域。这种方法可以直接从深度输入中预测机器人手臂上预定义关键点的3D坐标，并且推断速度较高（可达22 FPS），相比之下基于渲染与比对的方法更慢。然而，这种方法的准确性较低，并且所提出的表现形式在理论上受限于多相机通用性问题。总体而言，现有方法都面临这些局限性：

- 效率与性能之间的冲突。
- 跨摄像头泛化问题。


#h(2em)为了应对这些挑战，我们提出了一种名为RoboKeyGen的新框架。基本思想如图1所示。与之前的方法不同，我们将这一高维度预测任务分解为两个子任务：2D关键点检测和将2D关键点提升到3D。前者专注于从外观特征中提取2D关键点，而后者则集中于视角变换以及机器人的结构信息。这种分解使得我们的方法能够在保持基于关键点方法固有高效性的前提下提高性能。具体来说，首先预测预定义的关键点的2D投影。然后将这些投影映射到标准化摄像机坐标空间中。接下来，根据标准化的2D关键点生成3D关键点，再利用这些3D关键点回归关节角度。最后，使用现成的姿态拟合算法[14]来估计机器人姿态。

算法[14]被用于估计机器人姿态。得益于2D机器人关键点检测技术的显著进步[5]，我们更加关注如何将这些2D关键点提升到3D空间及多相机通用性的问题。直接回归方法由于其未能考虑由2D关键点检测误差带来的不确定性而表现不佳。因此，建模3D关键点的条件分布更为合理。利用基于扩散模型[15]、[16]、[13]的鲁棒分布特性，我们采用一个基于估计2D关键点的扩散模型来生成3D关键点。对于跨相机通用性问题，考虑到不同相机具有不同的内参参数和投影变换，我们引入了标准化相机坐标空间(NCCS)进行2D关键点对齐，从而有效解决了跨相机通用性的问题。为了评估此方法，我们提供了一个集成模拟训练数据与两台深度相机的现实世界数据集的工作流程。比较分析表明，在性能和速度指标上我们的模型均优于RoboPose [8]，进一步突显了其在跨相机通用性上的鲁棒性。


=== 基于学习的机器人姿态和关节角度估计

1) 已知关节角度的姿态估计：近年来，深度学习的发展提供了创新的方法用于从机器人姿态恢复。Dream [5] 使用卷积网络回归2D热图并通过透视-n-点（PnP）随机样方法求解器 [17] 计算姿态。SGTAPose [6] 结合了时间信息以解决姿态估计中的自遮挡问题。此外，CtRNet [7] 采用自监督框架，有效地缩小了仿真到现实的差距。值得注意的是，这些方法依赖于即时的关节角度反馈，从而限制了其适用性。

2) 姿态和关节角度联合估计：当未知关节角度时，方法分为两类：渲染与比对、3D 关键点检测。RoboPose [8] 提供了一种基于单张RGB图像进行姿态和关节角度估计的渲染与比对框架，但由于渲染限制其速度仅能达到1 FPS 的单帧推理速度。基于深度信息的方法 SPDH [9] 将2D 热图姿态估计扩展到3D，但仍面临跨摄像头挑战。相比之下，我们的方法结合了关键点方法的速度优势，并引入了一种新颖的条件性3D 关键点生成方法，相比SPDH [9] 更有效解决了跨摄像头问题。

=== 扩散模型
扩散模型在生成建模中引起了广泛关注。一些研究集中在理论方面，例如通过去噪评分匹配目标训练噪声条件评分网络（SMLD）[18]、[19]；另一些研究引入了使用正向和反向马尔可夫链的去噪扩散概率模型（DDPM）[20]、[21]。宋等人[22]综述了这些模型，提供了统一视角来解释上述方法。一些研究还探讨了扩散模型的多种应用场景，包括医学影像[23]、点云生成[15]、物体重组[16]、[24]、物体姿态估计[25]和人体姿态估计[26]。受到这些进展的启发，我们提出了一种基于扩散模型的新颖框架，用于机器人姿态和关节角度估算，并专门针对从二维关键点检测提升到条件生成三维关键点进行研究。据我们所知，我们的方法是通过扩散模型学习机器人手臂结构的第一项探索工作。


III. 方法

任务描述。给定一个RGB图像流 {I}，我们的目标是估计机器人姿态 {Γ = (R, T) ∈ SE(3)} 和关节角度 {θ ∈ R^n}（其中 n 表示关节角度的数量）。我们假设已知机器人手臂和相机的正向运动学、CAD 模型以及内参。概览。我们将原始的高维任务分解为两个更易于处理的低维度子任务：2D 关键点检测以及将 2D 关键点提升到 3D。首先，从 RGB 图像 I 中预测预定义的关键点 c 的 2D 投影。然后，将这些估计的关键点 c 对齐成 NCCS（归一化相机坐标空间）中的形式 c̃。接着，使用扩散模型 Φζ 来建模在给定归一化 2D 关键点 c̃ 的情况下相机空间中 3D 关键点 Xcam 的分布 (Pdata(Xcam|c̃))。最后，我们利用一个轻量回归网络来预测关节角度 θ，并恢复机器人空间中的 3D 关键点 Xrob。通过姿态拟合恢复机器人姿态。


2D 关键点检测与规范化

1. *2D 关键点检测：* 我们先从当前的 RGB 图像 I 和上一次估计出的 2D 关键点中检测预定义的关键点 c ∈ RN×2，其中 N 表示关键点的数量。为了使用于提取图像特征的 2D 检测网络（Ψω）专注于纯机器人臂，并避免背景纹理的干扰，我们首先采用了实时语义分割网络 PIDNet-L [27] 来分离出机器人臂。考虑到相邻帧中 2D 关键点的变化较小，然后我们将上一帧的估计关键点投影到基于正弦变换和浅层 MLPs 的位置先验嵌入 F 中 [28, 22]。接下来，利用编码-解码检测网络（Ψω）[29,30] 输入 RGB 图像 I、分割掩模以及位置嵌入 F，预测当前帧的关键点 c。

2. *2D 关键点规范化：* 对于具有可用的前向运动学和预定义关键点的机器人臂，我们发现 Pdata(Xcam|c) 存在一个问题：相同的 2D 投影 c 在不同内参的相机下会产生不同的 3D 地面真实值 (GT) 关键点，这使得分布 Pdata(X | c) 定义不明确。为解决这一问题，我们将关键点 c 投影到规范化摄像机坐标空间（NCCS）c̃ 中。具体来说，在已知相机内参后，

对于第i个二维关键点$c _(i ) =  \(u _(i )\, v _(i )\) subset  c $，
我们将其转换为$ tilde(c )_(i ) =  lr(\(  frac(u _(i ) -  c_x ,f_x )\, frac(v _(i ) -  c_y ,f_y ) \) ) $

根据大多数机器人中所遵循的针孔相机模型 ， 这一变换等价于$ tilde(c )_(i ) =  lr(\(  frac(x _(i ),z _(i ))\, frac(y _(i ),z _(i )) \) ) $， 其 中 $ \(x _(i )\, y _(i )\, z _(i )\) subset  X _(c a m ) $是第i个关键点在相机空间中的坐标 。 我们现在考虑新的联合分 布$ D ' =  \{ \( tilde(c )\, X _(c a m )\) =  \{ \(frac(x _(i ),z _(i ))\, frac(y _(i ),z _(i ))\)\} _(i = 1 )^(N )\, \(\{ x _(i )\, y _(i )\, z _(i )\} \} _(i = 1 )^(N )\) tilde  P _(d a t a )\( tilde(c )\, X _(c a m )\)\} $ 。在 $P _(d a t a )\(X _(c a m )|  tilde(c )\)$中 ， 我 们 观 察 到 条 件 tilde(c )与 相 机 内 参 是 解 耦 的 ， 因 为 其 形 式 仅 依 赖 于 相 机 空 间 中 的 坐 标 。 因 此 ， 在 这 种 情 况 下 ， 学 习 新 的 条 件 分 布 $P _(d a t a )\(X _(c a m ) |  tilde(c )\)$等 同 于 确 保 每 个 关 键 点 的 z 坐 标 。 换 言 之 ， 我 们 的 方 法 只 需 关 注 机 器 人 臂 架 的 结 构 ， 不 受 相 机 内 参 的 影 响 。 


// B. 基于扩散模型的条件三维关键点生成
// 本节将阐述如何在生成建模框架下，根据规范化后的二维关键点\(\tilde{c}\)抽样已定义的三维关键点\(X_{cam}\)。为简化起见，我们用\(X \in R^{N \times 3}\)表示相机空间中的三维关键点\(X_{cam}\)（如图2所示）。我们假设每张图像中的二维-三维关键点对是从隐式联合分布\(D = \{(\tilde{c}, X) \sim P_{data}(\tilde{c}, X)\}\)中采样的，我们的目标是建模条件分布\(P_{data}(X|\tilde{c})\)。

// 1）学习得分函数\(\Phi_\zeta\)：我们采用基于得分的扩散模型来拟合条件分布\(P_{data}(X| \tilde{c})\)。具体而言，我们将[22]中提出的保持方差的随机微分方程（VP SDE）用于构建一个连续时间依赖的扩散过程\(\{X(t)\}_{t=0}^T\)。初始状态\(X(0)\)源自于条件分布\(P_{data}(X|c)\)，而最终状态\(X(T)\)则来自扩散先验分布\(p_T\)。随着\(t\)的增加，序列\(\{X(t)\}_{t=0}^T\) 的表达式形式为：
#pagebreak()
#show: rest => columns(2, rest)
= 吴恩达机器学习
#v(0.5em)  
== 线性回归

#set terms(indent: 1em)
// #show terms: 
/ 输入特征 Input Feature : $x$
/ 输出标签 Output Label : $y$
/ 样本 Sample : $(x,y)$
/ 样本数量 Sample Number : $m$
/ 第i个样本 :$(x^(i),y^(i))$
// #show: rest => columns(1, rest)

// #pagebreak()
#bibliography("use.bib", title: [
参考文献#v(1em)
],style: "nature")
 